+++
title = "Advent of Code Day 3: Overengineering"
[taxonomies]
  tags = ["aoc2024", "rust"]
+++

So I'm doing Advent of Code this year, and hopefully we can stick through all 25 days. Day 3's problem was particularly interesting to me, and I did some silly (and hopefully somewhat clever) stuff that I think would be fun to write about.

Here we are.

I likely won't redescribe the puzzles in full - for that, just head over to [Advent of Code](https://adventofcode.com/2024) - but I will summarize the parts briefly.

### Part 1: This is where the fun begins

So the main goal of this problem is to, within a single line/string, find matches of `mul(num1, num2)` and sum up all of the multiplication operations, giving you your answer. The sample text they provide for this is:
```md #
xmul(2,4)%&mul[3,7]!@^do_not_mul(5,5)+mul(32,64]then(mul(11,8)mul(8,5))
```
which will eventually output `(2*4 + 5*5 + 11*8 + 8*5) = 161`

Initially, I thought I could do it with Regex, and you certainly could, but that didn't feel like a satisfying enough solution to me. One of my friends also challenged me to use just Rust's standard library and nothing else, so that removed the `regex` crate from contention entirely. My next idea, which is what I ended up going with, was to basically handwrite a lexer and do some nifty sliding window magic.

#### Step 1: Defining Tokens

First thing's first, we have to define the tokens we're going to be using. With a little bit of inspiration from the fantastic [Crafting Interpreters](https://craftinginterpreters.com/scanning.html), I ended up with the following:
```rust,hide_lines=7 8
enum Token {
    LPAREN,
    RPAREN,
    COMMA,
    NUMBER(u32),
    MUL,
    DO,
    DONT,
    OTHER, // throwaway
}
```

Clearly, the only tokens that make up something like `mul(num1, num2)` are `mul`, `(`, `,`, `)`, and numbers. Anything else is captured as `OTHER` and thrown away (handled, admittedly, in quite a disgraceful way. I wonder what my future employers would think).

#### Step 2: Lexing the damn thing

**Warning: there's gonna be a shitload of code below. I will explain it in a moment**

First, we set up the file reading and the iterator over our characters:
```rust
    let line = read_to_string(file).unwrap();
    let mut iter = line.chars().peekable();
    let mut tokens: Vec<Token> = Vec::new();
```
We call `peekable()` on our iterator because the `Peekable` struct provides us the `peek` method, which allows us to look at the next character without consuming it. This is particularly advantageous when we want to look ahead just once or twice in a controlled manner.

Now, here's where the magic happens!

```rust
while let Some(ch) = iter.next() {
    match ch {
        '(' => tokens.push(Token::LPAREN),
        ')' => tokens.push(Token::RPAREN),
        ',' => tokens.push(Token::COMMA),
        '1'..='9' => {
            let n: u32 = once(ch)
                .chain(from_fn(|| iter.by_ref()
                .next_if(|s| s.is_ascii_digit())))
                .collect::<String>()
                .parse()
                .unwrap();

            tokens.push(Token::NUMBER(n));
        }
        'm' => {
            let rest = next_chunk(&mut iter, 2);
            if rest == vec!['u', 'l'] {
                tokens.push(Token::MUL);
            }
        }
        'd' => {
            let next = iter.by_ref().next_if_eq(&'o');
            if next.is_some() {
                iter.peek();
                let next = iter.by_ref().next_if_eq(&'n');
                if next.is_some() {
                    let rest = next_chunk(&mut iter, 4);
                    if rest == vec!['\'', 't', '(', ')'] {
                        tokens.push(Token::DONT);
                    }
                } else {
                    let rest = next_chunk(&mut iter, 2);
                    if rest == vec!['(', ')'] {
                        tokens.push(Token::DO);
                    }
                }
            }
        }
        _ => tokens.push(Token::OTHER),
    }
}

```

This is a lot, so I'll break it down for the relevant chunks. Naturally, we start by iterating until there are no more characters to yield.


